{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to neural nets\n",
    "\n",
    "## 2. Multi-layer perceptron\n",
    "<figure align=\"middle\">\n",
    "    <img src=\"images/perceptron_2layers.png\" title=\"2-layer perceptron\" width=\"400px\">\n",
    "    <figcaption>Fig 1. Multi-layer perceptron with 1 hidden layer.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of a 2-layer perceptron: input layer plus hidden layer plus output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MLPerceptron:\n",
    "    \"\"\" A Multi-Layer Perceptron\"\"\"\n",
    "\n",
    "    def __init__(self, inputs, targets, nhidden, beta=1, momentum=0.9, outtype='logistic'):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        # Set up network size\n",
    "        self.nin = np.shape(inputs)[1]\n",
    "        self.nout = np.shape(targets)[1]\n",
    "        self.ndata = np.shape(inputs)[0]\n",
    "        self.nhidden = nhidden\n",
    "\n",
    "        self.beta = beta\n",
    "        self.momentum = momentum\n",
    "        self.outtype = outtype\n",
    "\n",
    "        # Initialise network\n",
    "        self.weights1 = (np.random.rand(self.nin + 1, self.nhidden) - 0.5) * 2 / np.sqrt(self.nin)\n",
    "        self.weights2 = (np.random.rand(self.nhidden + 1, self.nout) - 0.5) * 2 / np.sqrt(self.nhidden)\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, inputs, targets, eta, niterations):\n",
    "        \"\"\" Train the thing \"\"\"\n",
    "        # Add the bias node\n",
    "        inputs_with_bias = np.concatenate((inputs, -np.ones((self.ndata, 1))), axis=1)\n",
    "        change = range(self.ndata)\n",
    "\n",
    "        updatew1 = np.zeros((np.shape(self.weights1)))\n",
    "        updatew2 = np.zeros((np.shape(self.weights2)))\n",
    "\n",
    "        current_iteration = 0\n",
    "        for n in range(niterations):\n",
    "            current_iteration += 1\n",
    "            self.outputs = self.forward(inputs_with_bias)\n",
    "\n",
    "            error = 0.5 * np.sum((self.outputs - targets) ** 2)\n",
    "            \n",
    "            if (np.mod(n, 50) == 0):\n",
    "                print(\"Iteration: \", n+1, \" Error: \", error)\n",
    "\n",
    "            \n",
    "            # Compute delta between targets and outputs\n",
    "            # Different types of output neurons\n",
    "            if self.outtype == 'linear':\n",
    "                deltao = (self.outputs - targets) / self.ndata\n",
    "            elif self.outtype == 'logistic':\n",
    "                deltao = self.beta * (self.outputs - targets) * self.outputs * (1.0 - self.outputs)\n",
    "            elif self.outtype == 'softmax':\n",
    "                deltao = (self.outputs - targets) * (self.outputs * (-self.outputs) + self.outputs) / self.ndata\n",
    "            else:\n",
    "                print(\"error\")\n",
    "\n",
    "            \n",
    "            # Compute delta for each weight from input to hidden\n",
    "            deltah = self.hidden * self.beta * (1.0 - self.hidden) * (np.dot(deltao, np.transpose(self.weights2)))\n",
    "\n",
    "            # backpropagation of error\n",
    "            updatew1 = eta * (np.dot(np.transpose(inputs_with_bias), deltah[:, :-1])) + self.momentum * updatew1\n",
    "            updatew2 = eta * (np.dot(np.transpose(self.hidden), deltao)) + self.momentum * updatew2\n",
    "            self.weights1 -= updatew1\n",
    "            self.weights2 -= updatew2\n",
    "\n",
    "            cm, accuracy = self.confusion_matrix(inputs, targets)\n",
    "            if accuracy == 1.0:\n",
    "                break\n",
    "        print(\"Total {} iterations\".format(current_iteration))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Run the network forward \"\"\"\n",
    "\n",
    "        self.hidden = np.dot(inputs, self.weights1);\n",
    "        self.hidden = 1.0 / (1.0 + np.exp(-self.beta * self.hidden))\n",
    "        self.hidden = np.concatenate((self.hidden, -np.ones((np.shape(inputs)[0], 1))), axis=1)\n",
    "\n",
    "        outputs = np.dot(self.hidden, self.weights2);\n",
    "\n",
    "        # Different types of output neurons\n",
    "        if self.outtype == 'linear':\n",
    "            return outputs\n",
    "        elif self.outtype == 'logistic':\n",
    "            return 1.0 / (1.0 + np.exp(-self.beta * outputs))\n",
    "        elif self.outtype == 'softmax':\n",
    "            normalisers = np.sum(np.exp(outputs), axis=1) * np.ones((1, np.shape(outputs)[0]))\n",
    "            return np.transpose(np.transpose(np.exp(outputs)) / normalisers)\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "    def confusion_matrix(self, inputs, targets):\n",
    "        \"\"\"Confusion matrix\"\"\"\n",
    "\n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = np.concatenate((inputs, -np.ones((np.shape(inputs)[0], 1))), axis=1)\n",
    "        outputs = self.forward(inputs)\n",
    "\n",
    "        nclasses = np.shape(targets)[1]\n",
    "\n",
    "        if nclasses == 1:\n",
    "            nclasses = 2\n",
    "            outputs = np.where(outputs > 0.5, 1, 0)\n",
    "        else:\n",
    "            # 1-of-N encoding\n",
    "            outputs = np.argmax(outputs, 1)\n",
    "            targets = np.argmax(targets, 1)\n",
    "\n",
    "        cm = np.zeros((nclasses, nclasses))\n",
    "        for i in range(nclasses):\n",
    "            for j in range(nclasses):\n",
    "                cm[i, j] = np.sum(np.where(outputs == i, 1, 0) * np.where(targets == j, 1, 0))\n",
    "\n",
    "\n",
    "        return cm, np.trace(cm) / np.sum(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Learning AND\n",
    "This still learns a linear separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anddata = np.array([[0, 0, 0], [0, 1, 0], [1, 0, 0], [1, 1, 1]])\n",
    "\n",
    "p = MLPerceptron(anddata[:, 0:2], anddata[:, 2:3], 2)\n",
    "p.train(anddata[:, 0:2], anddata[:, 2:3], 0.25, 1001)\n",
    "\n",
    "print()\n",
    "cm, accuracy = p.confusion_matrix(anddata[:, 0:2], anddata[:, 2:3])\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Learning XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xordata = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 0]])\n",
    "q = MLPerceptron(xordata[:, 0:2], xordata[:, 2:3], 2, outtype='logistic')\n",
    "q.train(xordata[:, 0:2], xordata[:, 2:3], 0.25, 5001)\n",
    "\n",
    "print()\n",
    "cm, accuracy = q.confusion_matrix(xordata[:, 0:2], xordata[:, 2:3])\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure align=\"middle\">\n",
    "    <img src=\"images/mlp_XOR.png\" title=\"Separated XOR by hyperplane\" width=\"400px\">\n",
    "    <figcaption>Fig 2. Separated the linearly non-separable XOR by a hyperplane.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Breast cancer diagnosis\n",
    "\n",
    "The simple 2-layer perceptron implemented above is quite powerful.\n",
    "We are going to use it to classify mammography results into malignant and non-malignant. \n",
    "The dataset is from [here](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"wdbc.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def csv_to_array(file_name):\n",
    "    np_a = None\n",
    "    with open(file_name) as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        for row in readCSV:\n",
    "            class_label = 0\n",
    "            if row[0].strip()=='M':\n",
    "                class_label = 1\n",
    "            num_arr = [float(x) for x in row[1:]] + [class_label]\n",
    "\n",
    "            if np_a is None:\n",
    "                np_a = np.array(num_arr)\n",
    "            else:\n",
    "                np_a = np.c_[np_a, num_arr]\n",
    "\n",
    "    np_a = np.transpose(np_a)\n",
    "\n",
    "    return np_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_data = csv_to_array(data_file)\n",
    "n_rows = np.shape(bc_data)[0]\n",
    "n_cols = np.shape(bc_data)[1]\n",
    "print(\"Dataset contains\",n_rows,\"rows and\", n_cols,\"columns\")\n",
    "\n",
    "# keep target attribute 0 or 1\n",
    "target_a = bc_data[:,n_cols-1:n_cols ]\n",
    "\n",
    "# normalize data in each column by subtracting mean and dividing by variance\n",
    "bc_data = bc_data[:, 0:n_cols-1]\n",
    "bc_data = (bc_data - bc_data.mean(axis=0)) / bc_data.var(axis=0)\n",
    "\n",
    "bc_data = np.c_[bc_data,target_a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = MLPerceptron(bc_data[:, 0:n_cols-1], bc_data[:, n_cols-1:n_cols], 2, outtype=\"linear\")\n",
    "p.train(bc_data[:, 0:n_cols-1], bc_data[:, n_cols-1:n_cols], 0.0005, 1000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm, accuracy = p.confusion_matrix(bc_data[:, 0:n_cols-1], bc_data[:, n_cols-1:n_cols])\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print (\"Note that the accuracy is only on a training set (just for demo)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2020 Marina Barsky. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
