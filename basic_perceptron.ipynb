{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to neural nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input is a set of feature vectors and the known answers for each vector - targets. Neural nets take input data that is observable, recordable, and by extension knowable and transform it into a logical model that can predict any future data.\n",
    "\n",
    "The neural network is simply a one or more weights which can be multiplied by the input vector to output a prediction or a class label. Thus, neural nets are good both for the prediction and for the classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the prediction always correct? No, the network can make mistakes. But it can learn from its mistakes.\n",
    "\n",
    "How does the network learn?\n",
    "\n",
    "Trial and error! First, it tries to make a prediction. Then, it sees whether it was too high or too low. Finally, it changes the weight (up or down) to predict more\n",
    "accurately the next time it sees the same input. This can be thought of as a **predict-compare-learn** paradigm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will demonstrate this idea with the simplest possible neural network which contains a single neuron. This is called a *perceptron*. \n",
    "\n",
    "A feature vector is shown to this neuron. For each feature there is a weight, and the network predicts a target variable by multiplying each feature value by its weight and producing a weighted sum. \n",
    "\n",
    "For a simple case of binary classification, we will use an activation function *sign*: if the weighted sum is positive the neuron predicts class yes(1), and if the sum is negative it predicts no(0).\n",
    "\n",
    "<figure>\n",
    "    <img src=\"images/perceptron.png\" title=\"Simple Perceptron for 2D feature vector\" width=\"400px\">\n",
    "    <figcaption>Fig 1. Simple perceptron for classifying a vector of 2 features. Tranforms a weighted sum of features into a class using the <i>sign</i> function.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Implementation of a simple Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    \"\"\" A basic Perceptron\"\"\"\n",
    "\n",
    "    def __init__(self, inputs, targets):\n",
    "        \"\"\" Constructor - setups dimensions and initializes weights\"\"\"\n",
    "        # Set up network size\n",
    "        if np.ndim(inputs) > 1:\n",
    "            self.nIn = np.shape(inputs)[1]\n",
    "        else:\n",
    "            self.nIn = 1\n",
    "\n",
    "        if np.ndim(targets) > 1:\n",
    "            self.nOut = np.shape(targets)[1]\n",
    "        else:\n",
    "            self.nOut = 1\n",
    "\n",
    "        self.nData = np.shape(inputs)[0]\n",
    "\n",
    "        # Initialise network weights - random guess\n",
    "        self.weights = np.random.rand(self.nIn + 1, self.nOut) * 0.1 - 0.05\n",
    "\n",
    "        \n",
    "    # Use this to predict target for a given feature vector 'point'\n",
    "    def predict(self, point):\n",
    "        input_with_bias = np.concatenate((point, -np.ones((1, 1))), axis=1)\n",
    "        activations = self.forward(input_with_bias)\n",
    "        print(\"Prediction for input {} is {}:\".format(point, activations))\n",
    "\n",
    "        \n",
    "    # Train network\n",
    "    def train(self, inputs, targets, eta, nIterations):\n",
    "        \"\"\" Train the thing \"\"\"\n",
    "        # For each feature vector add one bias node\n",
    "        inputs = np.concatenate((inputs, -np.ones((self.nData, 1))), axis=1)\n",
    "\n",
    "        # Training: activation function - sign       \n",
    "        activations = self.forward(inputs)\n",
    "        for n in range(nIterations):\n",
    "            print(\"Iteration: \", n+1)\n",
    "            print(\"Current weights:\", self.weights.tolist())\n",
    "\n",
    "            print(\"Current activations:\",  activations.tolist())\n",
    "            print(\"Targets:\", targets.tolist())\n",
    "            print()\n",
    "\n",
    "            total_error = np.sum(activations - targets)\n",
    "            if total_error == 0:\n",
    "                break\n",
    "\n",
    "            # update weights\n",
    "            self.weights -= eta * np.dot(np.transpose(inputs), activations - targets)\n",
    "            activations = self.forward(inputs)\n",
    "\n",
    "        print(\"Targets:\", targets.tolist())\n",
    "        print(\"Final predictions:\", activations.tolist())\n",
    "\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Run the network forward \"\"\"\n",
    "        # Compute activations\n",
    "        activations = np.dot(inputs, self.weights)\n",
    "\n",
    "        # Threshold the activations\n",
    "        return np.where(activations > 0, 1, 0)\n",
    "\n",
    "    def confusion_matrix(self, inputs, targets):\n",
    "        \"\"\"Confusion matrix\"\"\"\n",
    "\n",
    "        # Add the bias node\n",
    "        inputs = np.concatenate((inputs, -np.ones((self.nData, 1))), axis=1)\n",
    "\n",
    "        outputs = np.dot(inputs, self.weights)\n",
    "\n",
    "        nClasses = np.shape(targets)[1]\n",
    "\n",
    "        if nClasses == 1:\n",
    "            nClasses = 2\n",
    "            outputs = np.where(outputs > 0, 1, 0)\n",
    "        else:\n",
    "            # 1-of-N encoding\n",
    "            outputs = np.argmax(outputs, 1)\n",
    "            targets = np.argmax(targets, 1)\n",
    "\n",
    "        cm = np.zeros((nClasses, nClasses))\n",
    "        for i in range(nClasses):\n",
    "            for j in range(nClasses):\n",
    "                cm[i, j] = np.sum(np.where(outputs == i, 1, 0) * np.where(targets == j, 1, 0))\n",
    "\n",
    "        print(\"Confusion matrix:\")\n",
    "        print(cm)\n",
    "        print(\"Accuracy:\", np.trace(cm) / np.sum(cm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Learning concept of OR\n",
    "<figure align=\"middle\">\n",
    "    <img src=\"images/perceptron_OR.png\" title=\"Decision boundary for OR\" width=\"400px\">\n",
    "    <figcaption>Fig 2. Perceptron can learn a decision boundary for OR data.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
    "\n",
    "# set up the size of the input vector and initial weights\n",
    "p = Perceptron(a[:, 0:2], a[:, 2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction before learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before training:\")\n",
    "test = np.array([[0, 0]])\n",
    "p.predict(test)\n",
    "print()\n",
    "test = np.array([[5, 0]])\n",
    "p.predict(test)\n",
    "print()\n",
    "test = np.array([[0, 3]])\n",
    "p.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now learns from data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.train(a[:, 0:2], a[:, 2:], 0.25, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.confusion_matrix(a[:, 0:2], a[:, 2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now can classify any input of OR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After training:\")\n",
    "test = np.array([[0, 0]])\n",
    "p.predict(test)\n",
    "print()\n",
    "test = np.array([[5, 0]])\n",
    "p.predict(test)\n",
    "print()\n",
    "test = np.array([[0, 3]])\n",
    "p.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Learning concept of AND\n",
    "<figure align=\"middle\">\n",
    "    <img src=\"images/perceptron_AND.png\" title=\"Decision boundary for AND\" width=\"400px\">\n",
    "    <figcaption>Fig 3. Perceptron can learn a decision boundary for AND data.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0, 0, 0], [0, 1, 0], [1, 0, 0], [1, 1, 1]])\n",
    "\n",
    "test = np.array([[0, 1]]) \n",
    "print(\"Before training:\")\n",
    "p.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.train(a[:, 0:2], a[:, 2:], 0.25, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.confusion_matrix(a[:, 0:2], a[:, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After training:\")\n",
    "p.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Concept of $x_1$ AND NOT $x_2$\n",
    "\n",
    "<figure align=\"middle\">\n",
    "    <img src=\"images/perceptron_AND_NOT.png\" title=\"Decision boundary for AND NOT\" width=\"200px\">\n",
    "    <figcaption>Fig 4. Perceptron should be able to learn a decision boundary for $x_1$ AND NOT $x_2$.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Concept of exclusive OR (XOR)\n",
    "<figure align=\"middle\">\n",
    "    <img src=\"images/perceptron_XOR.png\" title=\"XOR is not linearly separable\" width=\"400px\">\n",
    "    <figcaption>Fig 5. Decision boundary for $x_1$ XOR $x_2$.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 1, 1]])\n",
    "\n",
    "test = np.array([[0, 0]]) \n",
    "print(\"Before training:\")\n",
    "p.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.train(a[:, 0:2], a[:, 2:], 0.25, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron cannot learn XOR: in 2 dimensions XOR vectors are not linearly-separable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2020 Marina Barsky. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
